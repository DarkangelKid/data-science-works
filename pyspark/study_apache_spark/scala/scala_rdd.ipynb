{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://10.8.2.1:8089/proxy/application_1515394405830_3960\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.builder().\n",
    "    appName(\"scala_rdd\").\n",
    "    config(\"spark.executor.instances\",\"2\").\n",
    "    config(\"spark.executor.cores\",\"2\").\n",
    "    config(\"spark.executor.memory\", \"4g\").\n",
    "    config(\"spark.yarn.executor.memoryOverhead\", \"1g\").\n",
    "    getOrCreate()\n",
    "\n",
    "println(\"http://10.8.2.1:8089/proxy/\"+ spark.sparkContext.applicationId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 1,2,3,4\n",
      "After * 2: 2,4,6,8\n",
      "Filter even: 2,4\n"
     ]
    }
   ],
   "source": [
    "var rdd = spark.sparkContext.parallelize(Array(1, 2, 3, 4))\n",
    "println(\"Before: \" + rdd.collect().mkString(\",\"))\n",
    "println(\"After * 2: \" + rdd.map(_ * 2).collect().mkString(\",\"))\n",
    "println(\"Filter even: \" + rdd.filter(_ % 2 == 0).collect().mkString(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 1,2,2,3,4\n",
      "Distinct: 4,1,2,3\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(Array(1, 2, 2, 3, 4))\n",
    "println(\"Before: \" + rdd.collect().mkString(\",\"))\n",
    "println(\"Distinct: \" + rdd.distinct().collect().mkString(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 1,2,3\n",
      "To array:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(Array(1, 6), Array(2, 7), Array(3, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(Array(1, 2, 3))\n",
    "println(\"Before: \" + rdd.collect().mkString(\",\"))\n",
    "println(\"To array:\")\n",
    "rdd.map(x => Array(x, x + 5)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To flat array:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(1, 6, 2, 7, 3, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"To flat array:\")\n",
    "rdd.flatMap(x => Array(x, x + 5)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 1,2,3\n",
      "Reduce: 6\n",
      "Take 2: 1,2\n",
      "Collect: 1,2,3\n",
      "Count: 3\n"
     ]
    }
   ],
   "source": [
    "// Python rdd.reduce(lambda a, b: a * b)\n",
    "rdd = spark.sparkContext.parallelize(Array(1, 2, 3))\n",
    "println(\"Before: \" + rdd.collect().mkString(\",\"))\n",
    "println(\"Reduce: \" + rdd.reduce((a, b) => a * b))\n",
    "println(\"Take 2: \" + rdd.take(2).mkString(\",\"))\n",
    "println(\"Collect: \" + rdd.collect().mkString(\",\"))\n",
    "println(\"Count: \" + rdd.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key-Value RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((1,2), (3,10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val keyValReduceByKey = spark.sparkContext.parallelize(Seq((1, 2), (3, 4), (3, 6)))\n",
    "keyValReduceByKey.reduceByKey((a, b) => a + b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((1,a), (1,b), (2,c))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val keyValSortByKey = spark.sparkContext.parallelize(Seq((1, \"a\"), (2, \"c\"), (1, \"b\")))\n",
    "keyValSortByKey.sortByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((1,CompactBuffer(a, b)), (2,CompactBuffer(c)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val keyValGroupByKey = spark.sparkContext.parallelize(Seq((1, \"a\"), (2, \"c\"), (1, \"b\")))\n",
    "keyValGroupByKey.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((a,(1,2)), (a,(1,3)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val x = spark.sparkContext.parallelize(Seq((\"a\", 1), (\"b\", 4)))\n",
    "val y = spark.sparkContext.parallelize(Seq((\"a\", 2), (\"a\", 3)))\n",
    "x.join(y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((a,(1,Some(2))), (a,(1,Some(3))), (b,(4,None)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.leftOuterJoin(y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((a,(Some(1),2)), (a,(Some(1),3)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.rightOuterJoin(y).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((a,(Some(1),Some(2))), (a,(Some(1),Some(3))), (b,(Some(4),None)))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.fullOuterJoin(y).collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "file_extension": ".scala",
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
